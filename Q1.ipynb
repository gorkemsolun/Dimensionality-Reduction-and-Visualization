{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GE 461 Introduction to Data Science 2024\n",
    "# Dimensionality Reduction and Visulalization\n",
    "\n",
    "## Question 1\n",
    "\n",
    "### GÃ¶rkem Kadir Solun 22003214\n",
    "\n",
    "In this question, principal components analysis (PCA) is used to project the 784-dimensional\n",
    "data onto lower dimensional subspaces to observe the effect of dimensionality on the performance\n",
    "of the Gaussian classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:  (10000, 784)\n",
      "Labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# NOTE: This data may need to be configured to the correct path\n",
    "directory = os.getcwd()\n",
    "data_path = os.path.join(directory, \"data\\\\fashion_mnist_data.txt\")\n",
    "labels_path = os.path.join(directory, \"data\\\\fashion_mnist_labels.txt\")\n",
    "\n",
    "data = np.loadtxt(data_path)\n",
    "labels = np.loadtxt(labels_path)\n",
    "\n",
    "print(\"Data shape: \", data.shape)\n",
    "print(\"Labels shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (5000, 784)\n",
      "Training labels shape:  (5000,)\n",
      "Testing data shape:  (5000, 784)\n",
      "Testing labels shape:  (5000,)\n",
      "Unique labels:  [0. 1. 2. 3. 4. 5. 6. 7. 8. 9.]\n",
      "Number of unique labels:  10\n",
      "Number of unique labels in test set:  10\n",
      "Number of unique labels in training set:  10\n",
      "Label distribution in training set:  [500 500 500 500 500 500 500 500 500 500]\n",
      "Label distribution in test set:  [500 500 500 500 500 500 500 500 500 500]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "# We will use 50% of the data for training and 50% for testing,\n",
    "# stratified by the labels to ensure that the training and testing sets have the same distribution of labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data, labels, test_size=0.5, stratify=labels, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training data shape: \", X_train.shape)\n",
    "print(\"Training labels shape: \", y_train.shape)\n",
    "print(\"Testing data shape: \", X_test.shape)\n",
    "print(\"Testing labels shape: \", y_test.shape)\n",
    "print(\"Unique labels: \", np.unique(y_train))\n",
    "print(\"Number of unique labels: \", len(np.unique(y_train)))\n",
    "print(\"Number of unique labels in test set: \", len(np.unique(y_test)))\n",
    "print(\"Number of unique labels in training set: \", len(np.unique(y_train)))\n",
    "print(\"Label distribution in training set: \", np.bincount(y_train.astype(int)))\n",
    "print(\"Label distribution in test set: \", np.bincount(y_test.astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Centering the Data by Subtracting the Mean of the Whole Data From Each Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(data, axis=0)\n",
    "\n",
    "centered_data = data - mean\n",
    "centered_X_train = X_train - mean\n",
    "centered_X_test = X_test - mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
